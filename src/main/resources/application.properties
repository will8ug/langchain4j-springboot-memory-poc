server.port=8080

langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
langchain4j.open-ai.chat-model.api-key=${DASHSCOPE_API_KEY}
langchain4j.open-ai.chat-model.model-name=qwen-flash
langchain4j.open-ai.chat-model.temperature=0.7
langchain4j.open-ai.chat-model.max-tokens=5000
langchain4j.open-ai.chat-model.max-completion-tokens=10000
#langchain4j.open-ai.chat-model.log-requests=true
#langchain4j.open-ai.chat-model.log-responses=true

langchain4j.open-ai.streaming-chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
langchain4j.open-ai.streaming-chat-model.api-key=${DASHSCOPE_API_KEY}
langchain4j.open-ai.streaming-chat-model.model-name=qwen-plus
langchain4j.open-ai.streaming-chat-model.temperature=0.7
langchain4j.open-ai.streaming-chat-model.max-tokens=5000

logging.level.dev.langchain4j=DEBUG
logging.level.org.springframework.web=DEBUG
#logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n

# Mem0 Configuration
mem0.api.key=${MEM0_API_KEY}
mem0.app.id=langchain4j-springboot-poc
mem0.top.k=3
mem0.chat.memory.max-messages=20

# Available options: mem0, compression
chat.memory.provider=mem0
